{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec15db3b-995d-423c-89df-8acdb0789e0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Read all gold model_dataset parquet files built by main.py\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m md = \u001b[43mspark\u001b[49m.read.parquet(\u001b[33m\"\u001b[39m\u001b[33mdatamart/gold/model_dataset/gold_model_dataset_*.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRows:\u001b[39m\u001b[33m\"\u001b[39m, md.count(), \u001b[33m\"\u001b[39m\u001b[33m| Cols:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(md.columns))\n\u001b[32m     10\u001b[39m md.printSchema()\n",
      "\u001b[31mNameError\u001b[39m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Read all gold model_dataset parquet files built by main.py\n",
    "md = spark.read.parquet(\"datamart/gold/model_dataset/gold_model_dataset_*.parquet\")\n",
    "\n",
    "print(\"Rows:\", md.count(), \"| Cols:\", len(md.columns))\n",
    "md.printSchema()\n",
    "\n",
    "# Convert to pandas for EDA (safe since ~9k rows)\n",
    "pdf = md.toPandas()\n",
    "pdf[\"snapshot_date\"] = pd.to_datetime(pdf[\"snapshot_date\"])\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f46fc2-5c04-46eb-a85f-649fa8ad0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & config ---------------------------------------------------------\n",
    "import os, glob, json, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, roc_curve, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "DATA_GLOB = \"datamart/gold/model_dataset/gold_model_dataset_*.parquet\"\n",
    "ARTIFACT_DIR = Path(\"models\")\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def make_ohe():\n",
    "    \"\"\"Compat for scikit-learn versions: sparse_output (>=1.2) vs sparse (older).\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973653d3-afdd-4a14-84d4-08c2fc48da27",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No files found for pattern: datamart/gold/model_dataset/gold_model_dataset_*.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m paths = \u001b[38;5;28msorted\u001b[39m(glob.glob(DATA_GLOB))\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo files found for pattern: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_GLOB\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m df_list = [pd.read_parquet(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[32m      7\u001b[39m df = pd.concat(df_list, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No files found for pattern: datamart/gold/model_dataset/gold_model_dataset_*.parquet"
     ]
    }
   ],
   "source": [
    "# --- Load ---------------------------------------------------------------------\n",
    "paths = sorted(glob.glob(DATA_GLOB))\n",
    "if not paths:\n",
    "    raise FileNotFoundError(f\"No files found for pattern: {DATA_GLOB}\")\n",
    "\n",
    "df_list = [pd.read_parquet(p) for p in paths]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(\"Rows:\", len(df), \"Cols:\", df.shape[1])\n",
    "display(df.head(3))\n",
    "\n",
    "# Ensure snapshot_date as datetime\n",
    "if \"snapshot_date\" in df.columns:\n",
    "    df[\"snapshot_date\"] = pd.to_datetime(df[\"snapshot_date\"])\n",
    "else:\n",
    "    raise ValueError(\"Expected 'snapshot_date' column is missing.\")\n",
    "\n",
    "# Ensure target present and int\n",
    "if \"label\" not in df.columns:\n",
    "    raise ValueError(\"Expected 'label' target column is missing.\")\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41801fe-57d9-406d-a750-c22b60c36a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
